{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ULMFiT_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO+h+11bz8kUx8EbWi03Ql/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandakonet/ulmfit/blob/main/ULMFiT_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ULMFiT Example\n",
        "\n",
        "Based on tutorials from:\n",
        "* https://docs.fast.ai/tutorial.text.html\n",
        "* https://github.com/floleuerer/fastai_ulmfit\n",
        "* https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb"
      ],
      "metadata": {
        "id": "5SnlWcuqI0aS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will be a basic tutorial of how to use ULMFiT on the IMBD dataset. For further exploration into the capabilities of ULMFiT, I highly recommend the third linked website above.\n",
        "\n"
      ],
      "metadata": {
        "id": "1PMYTsi8JHSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "ALg8i3mGJSem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the notebook code, be sure to switch the runtime to GPU. (Edit > Notebook Settings > Hardware Accelerator = GPU)"
      ],
      "metadata": {
        "id": "Y5TLN8nASJJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you are using google colab, you will need to run this line & restart runtime\n",
        "# before importing fastai below\n",
        "!pip install fastai --upgrade"
      ],
      "metadata": {
        "id": "Tb2091cHK5_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y3gmFGpKIM8n"
      },
      "outputs": [],
      "source": [
        "from fastai.text.all import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in IMDB dataset and store in a `DataLoaders`"
      ],
      "metadata": {
        "id": "5CKFSHPxLJdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "#path.ls() # see information stored in this folder\n",
        "dls = TextDataLoaders.from_folder(path, valid='test', bs=8)\n",
        "dls.show_batch()"
      ],
      "metadata": {
        "id": "gy78-4TIJW3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we see that our data has been processed and tokenized, as evidence by the special tokens added:\n",
        "* xxbos: beginning of text\n",
        "* xxmaj: next work is capitalized"
      ],
      "metadata": {
        "id": "11vUlO4mMKwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune language model"
      ],
      "metadata": {
        "id": "KOHHEp1iO8Zd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the steps of ULMFiT: \n",
        "1. pretrain large language model\n",
        "2. fine-tune on domain data\n",
        "3. add classification task head\n",
        "\n",
        "The first step is already done for us on an AWD_LSTM model with Wiki-text data. The step we start with is 2, fine-tune on domain data.\n",
        "\n",
        "Below, we initialize a `Learner` with our data, the AWD_LSTM model, the metrics, and a default weight decay of 0.1 and drop_mult of 0.1"
      ],
      "metadata": {
        "id": "0VUxfsSAPCTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm = language_model_learner(dls, AWD_LSTM,\n",
        "                                  metrics=[accuracy, Perplexity()],\n",
        "                                  path=path,\n",
        "                                  wd=0.1, drop_mult=0.1).to_fp16()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "J0-c8hmgPReO",
        "outputId": "45dd489c-f842-48d9-9a17-8ceb26fe887d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:09<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin fine-tuning, all we need to do is set the number of epochs and the intial learning rate. NOte that the pretrained `Learner` is in a frozen state and only the head of the model will be trained. \n",
        "\n",
        "For the sake of time, I will only be training 4 epochs. More will be needed for better performance."
      ],
      "metadata": {
        "id": "AQOZR_KGPb-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm.unfreeze()\n",
        "learn_lm.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "id": "KBPETxREPfgG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once this is done, we save all of our model except the final layer that converts activations to probabilities of picking each token in our vocabulary.\n",
        "\n",
        "We save this final layer with `save_encoder`"
      ],
      "metadata": {
        "id": "wmjXdzpNTB0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm.save('finetuned_lm')\n",
        "learn_lm.save_encoder('finetuned_lm_enc')"
      ],
      "metadata": {
        "id": "ehSB1_OjTGJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune text classifier"
      ],
      "metadata": {
        "id": "khO0dHEuT3-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like before, we gather data again. This time, we need to include only vocab that was included in the fine-tuned model."
      ],
      "metadata": {
        "id": "UDRHYrKST-eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls_class = TextDataLoaders.from_folder(path, valid='test', text_vocab=dls.vocab)"
      ],
      "metadata": {
        "id": "97vZmXg_T7He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, we create a learner..."
      ],
      "metadata": {
        "id": "ocuu8IKWUDxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class = text_classifier_learner(dls_class, AWD_LSTM, drop_mult=0.5, metrics=accuracy)"
      ],
      "metadata": {
        "id": "j8tTQGjiUNIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and we load the previous encoder that we just saved!"
      ],
      "metadata": {
        "id": "t07aukvwUSxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class = learn_class.load_encoder('finetuned_lm_enc')"
      ],
      "metadata": {
        "id": "3owZ5DkOUVYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we fine-tune by freezing all but a few layers at a time until we unfreeze all. This is the gradual unfreezing step discussed in the paper. Note that we start with an initial learning rate here."
      ],
      "metadata": {
        "id": "Aogbe-qLUdPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class.fit_one_cycle(1, 2e-2)"
      ],
      "metadata": {
        "id": "za-gsD-_Uk8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze all but last two layer. Note that we are changing the learning rate for these layers compared to the previous by making them smaller! This is discriminative fine-tuning."
      ],
      "metadata": {
        "id": "HQ74HgY9VOiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class.freeze_to(-2)\n",
        "learn_class.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "metadata": {
        "id": "-o74QvtFVMrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfreeze all but last three layers"
      ],
      "metadata": {
        "id": "wRVpyBsTVS9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class.freeze_to(-3)\n",
        "learn_class.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "metadata": {
        "id": "Th1NS5G1VTHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, do entire model"
      ],
      "metadata": {
        "id": "kwtgVQ3CVX5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class.unfreeze()\n",
        "learn_class.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "metadata": {
        "id": "5D1rHY6EVZXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And save!"
      ],
      "metadata": {
        "id": "EOG5_VpmVl2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_class.save('learn_class_unfreezed_final')"
      ],
      "metadata": {
        "id": "4bB2BQzHVmbT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}